# Data Science and Analytics Tools and Platforms
Variety of curated data science and analytics tools and platforms

## General
- [Gainers, Losers, and Trends in Gartner 2019 Magic Quadrant for Data Science and Machine Learning Platforms](https://www.kdnuggets.com/2019/02/gartner-2019-mq-data-science-machine-learning-changes.html)

- [Magic Quadrant for Data Science and Machine Learning Platforms](https://www.gartner.com/doc/reprints?id=1-65OPDHH&ct=190125):
![Image of MQ](https://github.com/tunlusoy/Data-Science-Tools/blob/master/MQ%20for%20DS%20and%20ML%20Platforms%20-%20Gartner%202019.PNG)

## Azure ML Studio and Azure Notebooks
- [Getting Data into Azure Notebooks from GitHub](https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/08/25/getting-data-into-azure-notebooks-jupyter-in-the-classroom/)

- [Getting Started with Python in VS Code](https://code.visualstudio.com/docs/python/python-tutorial)

- [Installing Python Packages to Azure Notebooks](https://blogs.msdn.microsoft.com/uk_faculty_connection/2017/09/20/installing-python-packages-to-azure-notebooks/)

## Machine Learning Lifecycle
- [MLflow](https://github.com/mlflow): Open source platform for the machine learning lifecycle

## Automated Machine Learning Tools
- Data Robot
https://www.datarobot.com

- [RapidMiner (Auto Modeler)](https://www.rapidminer.com): Much like KNIME, RapidMiner operates through visual programming and is capable of manipulating, analyzing and modeling data. RapidMiner makes data science teams more productive through an open source platform for data prep, machine learning, and model deployment. Its unified data science platform accelerates the building of complete analytical workflows – from data prep to machine learning to model validation to deployment – in a single environment, dramatically improving efficiency and shortening the time to value for data science projects.

- Tazi.ai
https://tazi.ai/

- Spark Beyond
https://www.sparkbeyond.com/

## Python
- [Awesome Python](https://github.com/vinta/awesome-python): A curated list of 'awesome' Python frameworks, libraries, software and resources, with code covering just about everything you might use Python for.

- [The Algorithms](https://github.com/TheAlgorithms/Python): Examples of sorting and other common computer science algorithms implemented in Python, including links to visualizations of the algorithms in action. Useful for those swatting up for a technical interview.

- [100 Days of ML Coding](https://github.com/Avik-Jain/100-Days-Of-ML-Code): This repo is an eclectic mix of worksheets that walk users through the basics of getting started with machine learning, with links to the associated code samples and datasets, as well as to useful videos explaining key mathematical concepts.

- [Python Patterns](https://github.com/faif/python-patterns): A collection of design patterns and idioms in Python, with code examples and written explanations of what the code is doing and when each pattern is appropriate to use.

- [TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples): A useful reference for those getting started with Google's TensorFlow machine-learning software framework, offering a long list of code examples demonstrating everything from basic TensorFlow operations to building neural networks.

- [An Introduction to Scikit Learn: The Gold Standard of Python Machine Learning](https://towardsdatascience.com/an-introduction-to-scikit-learn-the-gold-standard-of-python-machine-learning-e2b9238a98ab): Scikit-learn provides a wide selection of supervised and unsupervised learning algorithms. Best of all, it’s by far the easiest and cleanest ML library.

- [PyTorch - Everything You Need to Know](https://www.cuelogic.com/blog/pytorch-in-10-mins): The latest release of Pytorch 1.0 by Facebook marks another major milestone for the open source Deep Learning platform. It is increasingly making it easier for developers to build Machine Learning capabilities into their applications while testing their code is real time.

## R
- [R developer's guide to Azure](https://docs.microsoft.com/en-us/azure/architecture/data-guide/technology-choices/r-developers-guide): 

## MatLab
- [Step by step guide to machine learning with matlab](https://www.mathworks.com/campaigns/offers/mastering-machine-learning-with-matlab.html?s_eid=PSB_20534): Get started with a MATLAB machine learning example presented in an easy-to-follow tutorial format.

  
## Open Source Data Tools
- [Knime](https://www.knime.com/): KNIME Analytics Platform is the leading open solution for data-driven innovation, helping you discover the potential hidden in your data, mine for fresh insights, or predict new futures. With more than 1000 modules, hundreds of ready-to-run examples, a comprehensive range of integrated tools, and the widest choice of advanced algorithms available, KNIME Analytics Platform is the perfect toolbox for any data scientist.

- [R Programming](https://www.r-project.org/): What if I tell you that Project R, a GNU project, is written in R itself? It’s primarily written in C and Fortran. And a lot of its modules are written in R itself. It’s a free software programming language and software environment for statistical computing and graphics. The R language is widely used among data miners for developing statistical software and data analysis. Ease of use and extensibility has raised R’s popularity substantially in recent years. Besides data mining, it provides statistical and graphical techniques, including linear and nonlinear modeling, classical statistical tests, time-series analysis, classification, clustering, and others.

- [Orange](https://orange.biolab.si/): Orange is open source data visualization and data analysis for novice and expert and provides interactive workflows with a large toolbox to create interactive workflows to analyze and visualize data. Orange is packed with different visualizations, from scatter plots, bar charts, trees, to dendrograms, networks and heat maps.

- [Pentaho](http://www.pentaho.com/): Pentaho addresses the barriers that block your organization's ability to get value from all your data. The platform simplifies preparing and blending any data and includes a spectrum of tools to easily analyze, visualize, explore, report and predict. Open, embeddable and extensible, Pentaho is architected to ensure that each member of your team — from developers to business users — can easily translate data into value.

- [Talend](https://www.talend.com/): Talend is the leading open source integration software provider to data-driven enterprises. Our customers connect anywhere, at any speed. From ground to cloud and batch to streaming, data or application integration, Talend connects at big data scale, 5x faster and at 1/5th the cost.

- [Weka](https://weka.wikispaces.com/): Weka, an open source software, is a collection of machine learning algorithms for data mining tasks. The algorithms can either be applied directly to a data set or called from your own JAVA code. It is also well suited for developing new machine learning schemes, since it was fully implemented in the JAVA programming language, plus supporting several standard data mining tasks. For someone who hasn’t coded for a while, Weka with its GUI provides the easiest transition into the world of Data Science. Being written in Java, those with Java experience can call the library into their code as well.

- [NodeXL](http://nodexl.codeplex.com/): NodeXL is a data visualization and analysis software of relationships and networks. NodeXL provides exact calculations. It is a free (not the pro one) and open-source network analysis and visualization software. It is one of the best statistical tools for data analysis which includes advanced network metrics, access to social media network data importers, and automation.

- [Gephi](https://gephi.org/): Gephi is also an open-source network analysis and visualization software package written in Java on the NetBeans platform. Think of the giant friendship maps you see that represent LinkedIn or Facebook connections. Gephi takes that a step further by providing exact calculations.

## Data Visualization Tools
- [Datawrapper](https://www.datawrapper.de/): Datawrapper is an online data-visualization tool for making interactive charts. Once you upload the data from CSV/PDF/Excel file or paste it directly into the field, Datawrapper will generate a bar, line, map or any other related visualization. Datawrapper graphs can be embedded into any website or CMS with ready-to-use embed codes. So many reporters and news organizations use Datawrapper to embed live charts into their articles. It is very easy to use and produces effective graphics.

- [Solver](http://www.solverglobal.com/): Solver specializes in providing world-class financial reporting, budgeting, and analysis with push-button access to all data sources that drive company-wide profitability. Solver provides BI360, which is available for cloud and on-premise deployment, focusing on four key analytics areas.

- [Qlik](http://www.qlik.com/us/): Qlik lets you create visualizations, dashboards, and apps that answer your company’s most important questions. Now you can see the whole story that lives within your data.

- [Tableau](https://www.tableau.com/): Tableau democratizes visualization in an elegantly simple and intuitive tool. It is exceptionally powerful in business because it communicates insights through data visualization. In the analytics process, Tableau's visuals allow you to quickly investigate a hypothesis, sanity checks your gut, and just go explore the data before embarking on a treacherous statistical journey.

- [Power BI](https://www.powerbi.com):

- [Google Fusion Tables](https://support.google.com/fusiontables/answer/2571232): Fusion Tables meet Google Spreadsheets cooler, larger, and much nerdier cousin. Google Fusion Tables is an incredible tool for data analysis, large data-set visualization, and mapping. Not surprisingly, Google's incredible mapping software plays a big role in pushing this tool onto the list. Take for instance this map, which I made to look at oil production platforms in the Gulf of Mexico.

- [Infogram](https://infogram.com/): Infogram offers over 35 interactive charts and more than 500 maps to help you visualize your data beautifully. Create a variety of charts including column, bar, pie, or word cloud. You can even add a map to your infographic or report to really impress your audience.

## Sentiment Tools
- [Opentext](http://www.opentext.com/): The OpenText Sentiment Analysis module is a specialized classification engine used to identify and evaluate subjective patterns and expressions of sentiment within textual content. The analysis is performed at the topic, sentence, and document level and is configured to recognize whether portions of text are factual or subjective and, in the latter case, if the opinion expressed within these pieces of content is positive, negative, mixed, or neutral.

- [Semantria](https://www.lexalytics.com/): Semantria is a tool that offers a unique service approach by gathering texts, tweets, and other comments from clients and analyzing them meticulously to derive actionable and highly valuable insights. Semantria offers text analysis via API and Excel plugin. It differs from Lexalytics in that it is offered via API and Excel plugin, and in that it incorporates a bigger knowledge base and uses deep learning.

- [Trackur](http://www.trackur.com/): Trackur’s automated sentiment analysis looks at the specific keyword you are monitoring and then determines if the sentiment towards that keyword is positive, negative or neutral with the document. That’s weighted the most in Trackur algorithm. It could use to monitor all social media and mainstream news, to gain executive insights through trends, keyword discovery, automated sentiment analysis and influence scoring.

- [SAS Sentiment Analysis](https://www.sas.com/en_us/software/sentiment-analysis.html): SAS sentiment analysis automatically extracts sentiments in real time or over a period of time with a unique combination of statistical modeling and rule-based natural language processing techniques. Built-in reports show patterns and detailed reactions. So you can hone in on the sentiments that are expressed. 
With ongoing evaluations, you can refine models and adjust classifications to reflect emerging topics and new terms relevant to your customers, organization or industry.

- [Opinion Crawl](http://opinioncrawl.net/): Opinion Crawl is an online sentiment analysis for current events, companies, products, and people. Opinion Crawl allows visitors to assess Web sentiment on a topic - a person, an event, a company or a product. You can enter a topic and get an ad-hoc sentiment assessment of it. For each topic, you get a pie chart showing current real-time sentiment, a list of the latest news headlines, a few thumbnail images, and a tag cloud of key semantic concepts that the public associates with the subject. The concepts allow you to see what issues or events drive the sentiment in a positive or negative way. For more in-depth assessment, the web crawlers would find the latest published content on many popular subjects and current public issues and calculate sentiment for them on an ongoing basis. Then the blog posts would show the trend of sentiment over time, as well as the Positive-to-Negative ratio.

## Data Preparation Tools

### Desktop

- [Tableau Prep](https://www.tableau.com/products/prep)

- [Alteryx](https://www.alteryx.com/)

- [Open Refine](http://openrefine.org/): OpenRefine (formerly Google Refine) is a powerful tool for working with messy data: cleaning it, transforming it from one format into another, and extending it with web services and external data. OpenRefine can help you explore large data sets with ease.

- [Easy Morph](https://easymorph.com/)

### Online

- [Paxata](https://www.paxata.com/)

- [Trifacta](https://www.trifacta.com/)

- [Clear Story Data](https://www.clearstorydata.com)

## Data Extraction Tools
- [Octoparse](https://www.octoparse.com/): Octoparse is a free and powerful website crawler used for extracting almost all kinds of data you need from the website. You can use Octoparse to rip a website with its extensive functionalities and capabilities. Its point-and-click UI helps non-programmers to quickly get used to Octoparse. It allows you to grab all the text from the website with AJAX, Javascript and thus you can download almost all the website content and save it as a structured format like EXCEL, TXT, HTML or your databases. More advanced, it has provided Scheduled Cloud Extraction which enables you to [extract the dynamic data in real time](https://www.octoparse.com/blog/extracting-dynamic-data-with-octoparse) and keep a tracking record.

- [Content Grabber](https://contentgrabber.com/): Content Graber is a web crawling software targeted at enterprises. It can extract content from almost any website and save it as structured data in a format of your choice, including Excel reports, XML, CSV, and most databases. It is more suitable for people with advanced programming skills, since it offers many powerful scripting editing, debugging interfaces for people in need. Users are allowed to use C# or VB.NET to debug or write scripts to control the crawling process programming.

- [Import.io](https://www.import.io/): Import.io is a paid web-based data extraction tool to pull information off of websites used to be something reserved for the nerds. Simply highlight what you want and Import.io walks you through and "learns" what you are looking for. From there, Import.io will dig, scrape, and pull data for you to analyze or export.

- [Parsehub](https://www.parsehub.com/): Parsehub is a great web crawler that supports collecting data from websites that use AJAX technologies, JavaScript, cookies and etc. Its machine learning technology can read, analyze and then transform web documents into relevant data. As a freeware, you can set up no more than five public projects in Parsehub. The paid subscription plans allow you to create at least 20 private projects for scraping websites.

- [Mozenda](http://www.mozenda.com/): Mozenda is a Cloud-based web scraping service. It provides many useful utility features for data extraction. Users will be allowed to upload extracted data to cloud storage.

## Special Use-Case Tools
- [Splunk](https://www.splunk.com/): Splunk is a software for searching, monitoring, and analyzing machine-generated big data, via a Web-style interface.

## Top Free Web Scraping Software
- [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/): Beautiful Soup is a Python library designed for web-scraping HTML and XML files. You can install this free web scraping software If you run Debian or Ubuntu system.

- [CrawlMaster](http://www.crawlmonster.com/): CrawlMonster is a free web scraping software for your website SEO. It enables you to scan websites for different kinds of data points.

- [Connotate](http://www.connotate.com/): Connotate provides a solution for automating web data scraping. You need to request a consultation by providing examples of the type of web information you want to scrape.

- [Common Crawl](http://commoncrawl.org/): Common Crawl provides open datasets of crawled websites. It contains raw web page data, extracted metadata, and text extractions.

- [Crawly](http://crawly.diffbot.com/): Crawly provides automatic service that scrapes a website and turns into structured data in the form of JSON or CSV.

- [Diffbot](https://www.diffbot.com/): Diffbot is an automated tool for scraping structured data from web pages and turning a website into an API. It’s usually for developers.

- [Dexi.io](https://dexi.io/): Dexi.io is a professional cloud web scraping software for automated big data refinery. It offers both free and professional plans. It will be a great option for handling JavaScript.

- [Data Scraping Studio](https://www.datascraping.co/): Data Scraping Studio is a free web scraping software to harvest data from web pages, html, xml, and pdf. The desktop client is currently available for Windows only.

- [Easy Web Extract](http://webextract.net/): Easy Web Extract is a visual web scraping software for business purposes. The unique feature of the software is the HTTP submitted form.

- [FMiner](http://www.fminer.com/): FMiner is a web scraping software with a visual diagram designer and it allows you to build a project with macro recorder.

- [Grabby](https://grabby.io/): Grabby is a web scraping service that helps you scrape all the email address from websites. It’s fully browser-based and no installation required.

- [Helium Scraper](http://www.heliumscraper.com/en/index.php?p=home): Helium Scraper is a visual web data scraping software that works pretty well when the association between elements is small.

- [Scrape.it](http://scrape.it/): Scrape. It is a node.js web scraping software for humans. It’s a cloud-based web data extraction tool.

- [ScraperWiki](https://scraperwiki.com/): ScraperWiki changes its name to QuickCode. The product designed by The Sensible Code Company, is a Python and R data analysis environment.

- [ScrapingHub](https://scrapinghub.com/): Scrapehub provides a cloud-based web scraping platform that allows developers to deploy and scale their crawlers on demand. It will be a great option if you are a developer.

- [Screen Scraper](http://www.screen-scraper.com/): Screen Scraper is a web scraping software for different kinds of scraping. It’s not easy to master the software if you are an inexperienced user. It will take much time to learn the software.

- [Salestools.io](https://salestools.io/): Salestools.io provide a web scraping software that helps sales performers to gather data on professional networks like LinkedIn, Angellist, Viadeo.

- [ScrapeHero](https://www.scrapehero.com/): ScrapeHero as an API provider enables you to turn websites into data. It’s a recent rebranding of an existing web scraping business.

- [UiPath](http://www.uipath.com/): UiPath is a robotic process automation software for free web scraping. It automates web and desktop data extraction out of most third-party Apps. You can install the robotic process automation software if you run a Windows system.

- [Web Content Extractor](http://www.newprosoft.com/): Web Content Extractor is an easy-to-use web scraping software for your private or enterprise purposes. It’s very easy to learn and master. It has a 14-day free trial.

- [WebHarvy Web Scraper](https://www.webharvy.com/): WebHarvy is a point-and-click web scraping software. It’s designed for non-programmers. The extractor doesn’t allow you to schedule.

- [Web Scraper.io](http://webscraper.io/): Web Scraper is a chrome browser extension built for scraping data from websites. It’s a free web scraping software for scraping dynamic web pages.

- [Web Sundrew](http://www.websundew.com/): WebSundew is a visual scraping tool that works for structured web data scraping. The Enterprise edition allows you to run the scraping at a remote Server and publish collected data through FTP.

- [Winautomation](http://www.winautomation.com/): Winautomation is a Windows web scraping tool that enables you to automate desktop and web-based tasks. The layout is clear and easy to follow.

- [Web Roots](https://webrobots.io/): Web Robots is a web scraping platform for scraping dynamiJavaScript-heavy websites. The software is currently in beta.
